{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b6b6e6",
   "metadata": {},
   "source": [
    "# Test Locally Built InterpretML Library\n",
    "\n",
    "This notebook is designed to help you test the `interpret` library after building it locally with your custom changes (e.g., a new C++ loss function).\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  You have successfully run `make build` and `make install` from the `/home/diego/Dropbox/DropboxGit/interpret/scripts/` directory.\n",
    "2.  You are running this notebook in the same Python environment where the local `interpret` package was installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e82cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterpretML library imported successfully.\n",
      "InterpretML version: 0.6.11\n",
      "InterpretML path: ['/home/diego/Dropbox/DropboxGit/interpret/python/interpret-core/interpret']\n"
     ]
    }
   ],
   "source": [
    "# Import the interpret library and check version\n",
    "try:\n",
    "    import interpret\n",
    "    from interpret import show # For visualizing explanations\n",
    "    # Attempt to import a core component, e.g., an explainer or data utility\n",
    "    from interpret.glassbox import ExplainableBoostingClassifier \n",
    "    from interpret.data import ClassHistogram # A data utility\n",
    "    \n",
    "    print(\"InterpretML library imported successfully.\")\n",
    "    print(f\"InterpretML version: {interpret.__version__}\")\n",
    "    # You can also check the path to see if it's from your local repository\n",
    "    print(f\"InterpretML path: {interpret.__path__}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing InterpretML: {e}\")\n",
    "    print(\"Please ensure you have correctly run 'make build' and 'make install' from the 'scripts' directory.\")\n",
    "    print(\"Also, verify that this notebook is using the Python environment where the package was installed.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during import: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810d0c2",
   "metadata": {},
   "source": [
    "## Basic Functionality Test\n",
    "\n",
    "Let's try to use a common component like the Explainable Boosting Machine (EBM) to see if the library loads and executes basic operations. If your C++ changes affect EBM or related core components, this is a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50035f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for EBM.\n",
      "EBM model trained successfully.\n",
      "\n",
      "Global Explanations obtained from EBM.\n",
      "\n",
      "Local Explanations for the first few test instances obtained.\n",
      "\n",
      "Basic EBM test complete.\n",
      "If your changes are related to EBM, observe its behavior and outputs carefully.\n",
      "EBM model trained successfully.\n",
      "\n",
      "Global Explanations obtained from EBM.\n",
      "\n",
      "Local Explanations for the first few test instances obtained.\n",
      "\n",
      "Basic EBM test complete.\n",
      "If your changes are related to EBM, observe its behavior and outputs carefully.\n"
     ]
    }
   ],
   "source": [
    "# Example: Using Explainable Boosting Machine (EBM)\n",
    "# This model often has performance-critical parts that might be implemented in C++.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate some synthetic classification data\n",
    "X, y = make_classification(n_samples=200, n_features=5, random_state=42)\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data prepared for EBM.\")\n",
    "\n",
    "try:\n",
    "    # Initialize and train an EBM\n",
    "    # If your new loss is for EBM, you might need to specify it here if applicable\n",
    "    ebm = ExplainableBoostingClassifier(random_state=42, feature_names=feature_names)\n",
    "    ebm.fit(X_train, y_train)\n",
    "    print(\"EBM model trained successfully.\")\n",
    "\n",
    "    # Get global explanations\n",
    "    ebm_global = ebm.explain_global()\n",
    "    print(\"\\nGlobal Explanations obtained from EBM.\")\n",
    "    # In a full Jupyter environment, you can visualize this:\n",
    "    # show(ebm_global)\n",
    "\n",
    "    # Get local explanations for a few instances\n",
    "    ebm_local = ebm.explain_local(X_test.head(), y_test[:len(X_test.head())])\n",
    "    print(\"\\nLocal Explanations for the first few test instances obtained.\")\n",
    "    # In a full Jupyter environment, you can visualize this:\n",
    "    # show(ebm_local)\n",
    "\n",
    "    print(\"\\nBasic EBM test complete.\")\n",
    "    print(\"If your changes are related to EBM, observe its behavior and outputs carefully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while testing EBM: {e}\")\n",
    "    print(\"This could indicate an issue with the compiled components or your changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1dbcb",
   "metadata": {},
   "source": [
    "## Test Your Specific Changes\n",
    "\n",
    "Now, add cells below to specifically test the new loss function or other C++ modifications you have implemented.\n",
    "\n",
    "For example, if you added a new loss function `my_custom_loss` to a specific model:\n",
    "1.  Initialize the model with `loss='my_custom_loss'`.\n",
    "2.  Train it on appropriate data.\n",
    "3.  Evaluate its performance and behavior (e.g., convergence, explanation stability, comparison with existing losses).\n",
    "4.  Check for any errors or unexpected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to test the 'negative_binomial' objective with synthetic count data...\n",
      "Using true alpha for data generation: 0.5\n",
      "\n",
      "Generated synthetic count data. X_reg_df.shape: (200, 3), y_count.shape: (200,)\n",
      "Sample of true log(mu): [1.05914597 3.4622728  1.11256429 1.51251532 2.18480984]\n",
      "Sample of true mu: [ 2.88390698 31.88937238  3.04214935  4.53813132  8.88895809]\n",
      "Sample of generated y_count: [ 3 31  4  2  2]\n",
      "Min/Max of p_param_numpy: 0.0032009701819838937, 0.9882505434175736\n",
      "N param for numpy: 2.0\n",
      "\n",
      "Initialized ExplainableBoostingRegressor with objective='negative_binomial' and alpha=0.5\n",
      "\n",
      "Successfully trained EBM with 'negative_binomial' objective.\n",
      "\n",
      "Comparison of first 5 true log(mu) vs predicted log(mu):\n",
      "Instance 0: True log(mu) = 1.0591, Predicted log(mu) = 2.7235\n",
      "Instance 1: True log(mu) = 3.4623, Predicted log(mu) = 48.4158\n",
      "Instance 2: True log(mu) = 1.1126, Predicted log(mu) = 6.9791\n",
      "Instance 3: True log(mu) = 1.5125, Predicted log(mu) = 6.5771\n",
      "Instance 4: True log(mu) = 2.1848, Predicted log(mu) = 8.4588\n",
      "\n",
      "MSE between true log(mu) and predicted log(mu): 242.0100\n",
      "\n",
      "Test completed. If MSE is low, it suggests the model is learning the underlying mean structure.\n",
      "Further tests should validate the mathematical correctness of the loss, gradient, and hessian implemented in C++ against known Negative Binomial properties.\n",
      "\n",
      "Successfully trained EBM with 'negative_binomial' objective.\n",
      "\n",
      "Comparison of first 5 true log(mu) vs predicted log(mu):\n",
      "Instance 0: True log(mu) = 1.0591, Predicted log(mu) = 2.7235\n",
      "Instance 1: True log(mu) = 3.4623, Predicted log(mu) = 48.4158\n",
      "Instance 2: True log(mu) = 1.1126, Predicted log(mu) = 6.9791\n",
      "Instance 3: True log(mu) = 1.5125, Predicted log(mu) = 6.5771\n",
      "Instance 4: True log(mu) = 2.1848, Predicted log(mu) = 8.4588\n",
      "\n",
      "MSE between true log(mu) and predicted log(mu): 242.0100\n",
      "\n",
      "Test completed. If MSE is low, it suggests the model is learning the underlying mean structure.\n",
      "Further tests should validate the mathematical correctness of the loss, gradient, and hessian implemented in C++ against known Negative Binomial properties.\n"
     ]
    }
   ],
   "source": [
    "# Test the custom \"negative_binomial\" objective with synthetic count data\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Attempting to test the 'negative_binomial' objective with synthetic count data...\")\n",
    "\n",
    "# 1. Define true alpha (dispersion coefficient for Var(Y) = mu + alpha*mu^2)\n",
    "alpha_true = 0.5  # Example value for alpha\n",
    "print(f\"Using true alpha for data generation: {alpha_true}\")\n",
    "\n",
    "# 2. Generate synthetic features X\n",
    "n_samples = 200\n",
    "n_features = 3\n",
    "X_reg, _ = make_regression(n_samples=n_samples, n_features=n_features, n_informative=n_features, random_state=42, noise=0.1)\n",
    "feature_names_reg = [f\"reg_feature_{i}\" for i in range(X_reg.shape[1])]\n",
    "X_reg_df = pd.DataFrame(X_reg, columns=feature_names_reg)\n",
    "\n",
    "# 3. Create true underlying log(mu) values\n",
    "# Define some true coefficients for the linear combination\n",
    "true_intercept = 0.5\n",
    "true_coeffs = np.array([1.5, -0.5, 0.8])\n",
    "log_mu_true = true_intercept + X_reg_df.dot(true_coeffs)\n",
    "\n",
    "# 4. Calculate true mean mu\n",
    "mu_true = np.exp(log_mu_true)\n",
    "\n",
    "# 5. Generate count data y from Negative Binomial distribution\n",
    "# For numpy.random.negative_binomial(n_successes, p_success_prob):\n",
    "# n_successes (size parameter r) = 1 / alpha_true\n",
    "# p_success_prob = n_successes / (n_successes + mu_true) = (1/alpha_true) / (1/alpha_true + mu_true) = 1 / (1 + alpha_true * mu_true)\n",
    "n_param_numpy = 1.0 / alpha_true\n",
    "p_param_numpy = 1.0 / (1.0 + alpha_true * mu_true)\n",
    "\n",
    "# Ensure p is valid (0 < p <= 1)\n",
    "p_param_numpy = np.clip(p_param_numpy, 1e-9, 1.0) \n",
    "\n",
    "y_count = np.random.negative_binomial(n_param_numpy, p_param_numpy, size=n_samples)\n",
    "\n",
    "print(f\"\\nGenerated synthetic count data. X_reg_df.shape: {X_reg_df.shape}, y_count.shape: {y_count.shape}\")\n",
    "print(f\"Sample of true log(mu): {log_mu_true.head().values}\")\n",
    "print(f\"Sample of true mu: {mu_true.head().values}\")\n",
    "print(f\"Sample of generated y_count: {y_count[:5]}\")\n",
    "print(f\"Min/Max of p_param_numpy: {np.min(p_param_numpy)}, {np.max(p_param_numpy)}\")\n",
    "print(f\"N param for numpy: {n_param_numpy}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Initialize ExplainableBoostingRegressor with the custom objective\n",
    "    ebm_nb = ExplainableBoostingRegressor(\n",
    "        # this is the way to specify a parameter for an objective in EBM\n",
    "        objective=f\"negative_binomial:alpha={alpha_true}\", # Specify the custom objective with alpha\n",
    "        feature_names=feature_names_reg, # Pass feature names\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"\\nInitialized ExplainableBoostingRegressor with objective='negative_binomial' and alpha={alpha_true}\")\n",
    "\n",
    "    # Fit the model\n",
    "    ebm_nb.fit(X_reg_df, y_count)\n",
    "    print(\"\\nSuccessfully trained EBM with 'negative_binomial' objective.\")\n",
    "\n",
    "    # Predict log(mu_pred)\n",
    "    log_mu_pred = ebm_nb.predict(X_reg_df)\n",
    "    print(\"\\nComparison of first 5 true log(mu) vs predicted log(mu):\")\n",
    "    for i in range(5):\n",
    "        print(f\"Instance {i}: True log(mu) = {log_mu_true.iloc[i]:.4f}, Predicted log(mu) = {log_mu_pred[i]:.4f}\")\n",
    "    \n",
    "    mse_log_mu = np.mean((log_mu_true - log_mu_pred)**2)\n",
    "    print(f\"\\nMSE between true log(mu) and predicted log(mu): {mse_log_mu:.4f}\")\n",
    "\n",
    "    print(\"\\nTest completed. If MSE is low, it suggests the model is learning the underlying mean structure.\")\n",
    "    print(\"Further tests should validate the mathematical correctness of the loss, gradient, and hessian implemented in C++ against known Negative Binomial properties.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while testing the 'negative_binomial' objective: {e}\")\n",
    "    print(\"Check the following:\")\n",
    "    print(\"1. The 'negative_binomial' objective is correctly registered in 'objective_registrations.hpp'.\")\n",
    "    print(\"2. The 'NegativeBinomialObjective.hpp' class constructor matches the registration parameters (e.g., takes 'alpha').\")\n",
    "    print(\"3. The library was successfully rebuilt and reinstalled ('make build' and 'make install').\")\n",
    "    print(\"4. The Python environment for this notebook is the one where the local build was installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc6c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136fe1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m fig = px.histogram(x = mu_true / log_mu_pred, nbins=\u001b[32m50\u001b[39m, labels={\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mmu_true / log_mu_pred\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m      2\u001b[39m fig.update_layout(title_text=\u001b[33m'\u001b[39m\u001b[33mHistogram of True Mu / Predicted Log Mu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/DropboxGit/interpret/.venv/lib/python3.12/site-packages/plotly/basedatatypes.py:3436\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3403\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3404\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3405\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3432\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3434\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3436\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/DropboxGit/interpret/.venv/lib/python3.12/site-packages/plotly/io/_renderers.py:425\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    421\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    422\u001b[39m     )\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    426\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    427\u001b[39m     )\n\u001b[32m    429\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    431\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "\n",
    "# fig = px.histogram(x = mu_true / log_mu_pred, nbins=50, labels={'x':'mu_true / log_mu_pred'})\n",
    "# fig.update_layout(title_text='Histogram of True Mu / Predicted Log Mu')\n",
    "# fig.show()\n",
    "\n",
    "# Use matplotlib.pyplot for the histogram\n",
    "plt.figure()\n",
    "plt.hist(mu_true / log_mu_pred, bins=50)\n",
    "plt.xlabel('mu_true / log_mu_pred')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of True Mu / Predicted Log Mu')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
