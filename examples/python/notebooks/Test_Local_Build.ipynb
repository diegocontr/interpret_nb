{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b6b6e6",
   "metadata": {},
   "source": [
    "# Test Locally Built InterpretML Library\n",
    "\n",
    "This notebook is designed to help you test the `interpret` library after building it locally with your custom changes (e.g., a new C++ loss function).\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  You have successfully run `make build` and `make install` from the `/home/diego/Dropbox/DropboxGit/interpret/scripts/` directory.\n",
    "2.  You are running this notebook in the same Python environment where the local `interpret` package was installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e82cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InterpretML library imported successfully.\n",
      "InterpretML version: 0.6.10\n",
      "InterpretML path: ['/home/diego/Dropbox/DropboxGit/interpret/python/interpret-core/interpret']\n"
     ]
    }
   ],
   "source": [
    "# Import the interpret library and check version\n",
    "try:\n",
    "    import interpret\n",
    "    from interpret import show # For visualizing explanations\n",
    "    # Attempt to import a core component, e.g., an explainer or data utility\n",
    "    from interpret.glassbox import ExplainableBoostingClassifier \n",
    "    from interpret.data import ClassHistogram # A data utility\n",
    "    \n",
    "    print(\"InterpretML library imported successfully.\")\n",
    "    print(f\"InterpretML version: {interpret.__version__}\")\n",
    "    # You can also check the path to see if it's from your local repository\n",
    "    print(f\"InterpretML path: {interpret.__path__}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing InterpretML: {e}\")\n",
    "    print(\"Please ensure you have correctly run 'make build' and 'make install' from the 'scripts' directory.\")\n",
    "    print(\"Also, verify that this notebook is using the Python environment where the package was installed.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during import: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810d0c2",
   "metadata": {},
   "source": [
    "## Basic Functionality Test\n",
    "\n",
    "Let's try to use a common component like the Explainable Boosting Machine (EBM) to see if the library loads and executes basic operations. If your C++ changes affect EBM or related core components, this is a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50035f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for EBM.\n",
      "EBM model trained successfully.\n",
      "\n",
      "Global Explanations obtained from EBM.\n",
      "\n",
      "Local Explanations for the first few test instances obtained.\n",
      "\n",
      "Basic EBM test complete.\n",
      "If your changes are related to EBM, observe its behavior and outputs carefully.\n"
     ]
    }
   ],
   "source": [
    "# Example: Using Explainable Boosting Machine (EBM)\n",
    "# This model often has performance-critical parts that might be implemented in C++.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate some synthetic classification data\n",
    "X, y = make_classification(n_samples=200, n_features=5, random_state=42)\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data prepared for EBM.\")\n",
    "\n",
    "try:\n",
    "    # Initialize and train an EBM\n",
    "    # If your new loss is for EBM, you might need to specify it here if applicable\n",
    "    ebm = ExplainableBoostingClassifier(random_state=42, feature_names=feature_names)\n",
    "    ebm.fit(X_train, y_train)\n",
    "    print(\"EBM model trained successfully.\")\n",
    "\n",
    "    # Get global explanations\n",
    "    ebm_global = ebm.explain_global()\n",
    "    print(\"\\nGlobal Explanations obtained from EBM.\")\n",
    "    # In a full Jupyter environment, you can visualize this:\n",
    "    # show(ebm_global)\n",
    "\n",
    "    # Get local explanations for a few instances\n",
    "    ebm_local = ebm.explain_local(X_test.head(), y_test[:len(X_test.head())])\n",
    "    print(\"\\nLocal Explanations for the first few test instances obtained.\")\n",
    "    # In a full Jupyter environment, you can visualize this:\n",
    "    # show(ebm_local)\n",
    "\n",
    "    print(\"\\nBasic EBM test complete.\")\n",
    "    print(\"If your changes are related to EBM, observe its behavior and outputs carefully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while testing EBM: {e}\")\n",
    "    print(\"This could indicate an issue with the compiled components or your changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1dbcb",
   "metadata": {},
   "source": [
    "## Test Your Specific Changes\n",
    "\n",
    "Now, add cells below to specifically test the new loss function or other C++ modifications you have implemented.\n",
    "\n",
    "For example, if you added a new loss function `my_custom_loss` to a specific model:\n",
    "1.  Initialize the model with `loss='my_custom_loss'`.\n",
    "2.  Train it on appropriate data.\n",
    "3.  Evaluate its performance and behavior (e.g., convergence, explanation stability, comparison with existing losses).\n",
    "4.  Check for any errors or unexpected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the custom \"negative_binomial\" objective\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Attempting to test the 'negative_binomial' objective...\")\n",
    "\n",
    "# Generate synthetic regression data\n",
    "# For Negative Binomial with a log link, y should be positive counts.\n",
    "# We'll generate general regression data and transform y to be positive.\n",
    "X_reg, y_reg = make_regression(n_samples=100, n_features=3, random_state=42, noise=0.1)\n",
    "\n",
    "# Ensure y_reg is positive for the log link used by negative_binomial\n",
    "# (actual negative binomial loss expects counts, but this is a structural test)\n",
    "y_reg_positive = np.abs(y_reg) + 1.0 \n",
    "\n",
    "feature_names_reg = [f\"reg_feature_{i}\" for i in range(X_reg.shape[1])]\n",
    "X_reg_df = pd.DataFrame(X_reg, columns=feature_names_reg)\n",
    "\n",
    "print(f\"\\nGenerated regression data. X_reg_df.shape: {X_reg_df.shape}, y_reg_positive.shape: {y_reg_positive.shape}\")\n",
    "print(f\"Sample y_reg_positive values: {y_reg_positive[:5]}\")\n",
    "\n",
    "try:\n",
    "    # Initialize ExplainableBoostingRegressor with the custom objective\n",
    "    # The 'negative_binomial' objective is registered to take an 'alpha' parameter.\n",
    "    ebm_nb = ExplainableBoostingRegressor(\n",
    "        objective=\"negative_binomial\",\n",
    "        # objective_params are passed directly to the C++ constructor\n",
    "        # For \"negative_binomial\", we registered it with an \"alpha\" parameter.\n",
    "        objective_params={\"alpha\": 1.5}, # Example alpha value\n",
    "        feature_names=feature_names_reg,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"\\nInitialized ExplainableBoostingRegressor with objective='negative_binomial' and alpha=1.5\")\n",
    "\n",
    "    # Fit the model\n",
    "    ebm_nb.fit(X_reg_df, y_reg_positive)\n",
    "    print(\"\\nSuccessfully trained EBM with 'negative_binomial' objective.\")\n",
    "    print(\"This indicates the objective was found and the model training process initiated without crashing.\")\n",
    "    print(\"Further tests should validate the mathematical correctness of the loss, gradient, and hessian if they were implemented.\")\n",
    "\n",
    "    # Optionally, you can try to get explanations if the model trained\n",
    "    # ebm_nb_global = ebm_nb.explain_global()\n",
    "    # print(\"\\nGlobal explanations obtained.\")\n",
    "    # from interpret import show\n",
    "    # show(ebm_nb_global)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while testing the 'negative_binomial' objective: {e}\")\n",
    "    print(\"Check the following:\")\n",
    "    print(\"1. The 'negative_binomial' objective is correctly registered in 'objective_registrations.hpp'.\")\n",
    "    print(\"2. The 'NegativeBinomialObjective.hpp' class constructor matches the registration parameters (e.g., takes 'alpha').\")\n",
    "    print(\"3. The library was successfully rebuilt and reinstalled ('make build' and 'make install').\")\n",
    "    print(\"4. The Python environment for this notebook is the one where the local build was installed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
